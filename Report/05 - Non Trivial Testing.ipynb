{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempted use of non-trivial imputation\n",
    "\n",
    "We attempted to use the R package `mice` for data imputation. This package has a variety of different methods for predicting missing values in a dataset, the first of which I tried was \"predictive mean matching\" which is used for numerical variables. There are also many other methods that you can specify in this package allowing for different imputation methods, however we ran into many problems trying to get any of these to work successfully. Many different errors were observed, due to non-invertability, and the handling of categorical variables. We tried to fix this by removing discrete data from the dataset, as the ip address counted as it's own categorical data, and therefore in the imputation process would generate over 700 dummy variables, which was not ideal, as not only did the process fail, but it took a long time to even reach this conclusion, freezing computers and filling the memory in the process.\n",
    "\n",
    "Further evidence of this attempted implementation can be found in this [file](https://github.com/Galeforse/DST-Assessment-02/blob/main/Gabriel%20Grant/Extra%20testing%20on%20MICE.ipynb), if you so wish to observe some of the attempts made.\n",
    "\n",
    "Both `mice`, and the `amelia` package which did generate some results (found later in this document), are both examples of multiple imputation which you can specify within each function (generally I used `n=5`). This generates multiple implementations, of which you can then choose the best or \"complete\" to combine them together into a completely predicted model.\n",
    "\n",
    "From the package description: \"*The MICE algorithm can impute mixes of continuous, binary, unordered categorical and ordered categorical data. In addition, MICE can impute continuous two-level data, and maintain consistency between imputations by means of passive imputation. Many diagnostic plots are implemented to inspect the quality of the imputations.*\"\n",
    "\n",
    "This made me think it would be suitable for usage with our data however after many failed attempts I decided to move on with other work in the project.\n",
    "\n",
    "## Amelia\n",
    "\n",
    "I also attempted to use the `amelia` package. This package again uses multiple imputation to predict missing values. The model assumes that the complete data is multivariate normal; a common assumption amongst missing data, but not necessarily true. The algorithm itself computes missing data by drawing from data that is already available and calculating the likelihood that a value would fit into the missing data slot.\n",
    "\n",
    "Again in this instance I could only get the function to work upon removal of all categorical data and it resulted in not particularly good looking predictions for any variable other than the logduration, what follows is the general structure of what was attempted on the testing data that we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: 'lubridate'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "Loading required package: mice\n",
      "\n",
      "\n",
      "Attaching package: 'mice'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    cbind, rbind\n",
      "\n",
      "\n",
      "Registered S3 method overwritten by 'quantmod':\n",
      "  method            from\n",
      "  as.zoo.data.frame zoo \n",
      "\n",
      "\n",
      "Attaching package: 'dlookr'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    transform\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Loading required package: colorspace\n",
      "\n",
      "Loading required package: grid\n",
      "\n",
      "VIM is ready to use.\n",
      "\n",
      "\n",
      "Suggestions and bug-reports can be submitted at: https://github.com/statistikat/VIM/issues\n",
      "\n",
      "\n",
      "Attaching package: 'VIM'\n",
      "\n",
      "\n",
      "The following object is masked from 'package:datasets':\n",
      "\n",
      "    sleep\n",
      "\n",
      "\n",
      "Loading required package: Rcpp\n",
      "\n",
      "## \n",
      "## Amelia II: Multiple Imputation\n",
      "## (Version 1.7.6, built: 2019-11-24)\n",
      "## Copyright (C) 2005-2020 James Honaker, Gary King and Matthew Blackwell\n",
      "## Refer to http://gking.harvard.edu/amelia/ for more information\n",
      "## \n",
      "\n",
      "Loading required package: survival\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(lubridate)\n",
    "library(dlookr)\n",
    "library(dplyr)\n",
    "library(mice)\n",
    "library(VIM)\n",
    "library(Amelia)\n",
    "library(Zelig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Data imported in:\"\n",
      "[1] \"3.53S\"\n"
     ]
    }
   ],
   "source": [
    "temp2 <- tempfile()\n",
    "start <- proc.time()\n",
    "download.file(\"https://github.com/Galeforse/DST-Assessment-02/raw/main/Data/test_missing1.csv.gz\",temp2)\n",
    "data <- (read.csv(gzfile(temp2)))\n",
    "print(\"Data imported in:\")\n",
    "print(seconds_to_period((proc.time()-start)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t194980 obs. of  17 variables:\n",
      " $ ts           : num  1.33e+09 1.33e+09 1.33e+09 1.33e+09 1.33e+09 ...\n",
      " $ orig_ip      : Factor w/ 200 levels \"::\",\"0.0.0.0\",..: 15 15 21 106 21 81 106 21 21 81 ...\n",
      " $ orig_port    : num  2633 4094 16066 42997 38566 ...\n",
      " $ resp_ip      : Factor w/ 2913 levels \"10.10.0.7\",\"10.10.10.10\",..: 1382 1523 2327 1269 1187 1187 533 953 2327 1186 ...\n",
      " $ resp_port    : num  80 80 12486 28745 32754 ...\n",
      " $ proto        : Factor w/ 3 levels \"icmp\",\"tcp\",\"udp\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ service      : chr  \"http\" \"\" \"\" \"\" ...\n",
      " $ duration     : num  NA 0.01 NA NA NA NA NA NA NA 0.01 ...\n",
      " $ orig_bytes   : num  NA 7085 NA NA NA ...\n",
      " $ resp_bytes   : num  NA 172 NA NA NA NA NA NA NA 0 ...\n",
      " $ conn_state   : Factor w/ 13 levels \"OTH\",\"REJ\",\"RSTO\",..: 3 3 2 2 2 2 2 2 2 2 ...\n",
      " $ missed_bytes : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ history      : Factor w/ 251 levels \"-\",\"a\",\"A\",\"Aa\",..: 86 86 251 251 251 251 251 251 251 251 ...\n",
      " $ orig_pkts    : num  8 10 1 1 1 1 1 1 1 1 ...\n",
      " $ orig_ip_bytes: num  813 7497 48 60 48 ...\n",
      " $ resp_pkts    : num  9 9 1 1 1 1 1 1 1 1 ...\n",
      " $ resp_ip_bytes: num  8505 544 40 40 40 ...\n"
     ]
    }
   ],
   "source": [
    "dat <- data %>%\n",
    "    mutate(\n",
    "        ts = as.numeric(ts),\n",
    "        orig_ip = as.factor(orig_ip),\n",
    "        resp_ip = as.factor(resp_ip),\n",
    "        orig_port = as.numeric(orig_port),\n",
    "        resp_port = as.numeric(resp_port),\n",
    "        proto = as.factor(proto),\n",
    "        conn_state = as.factor(conn_state),\n",
    "        history = as.factor(history),\n",
    "        duration = as.numeric(duration),\n",
    "        orig_bytes = as.numeric(orig_bytes),\n",
    "        resp_bytes = as.numeric(resp_bytes),\n",
    "        missed_bytes = as.numeric(missed_bytes),\n",
    "        orig_pkts = as.numeric(orig_pkts),\n",
    "        resp_pkts = as.numeric(resp_pkts),\n",
    "        orig_ip_bytes = as.numeric(orig_ip_bytes),\n",
    "        resp_ip_bytes = as.numeric(resp_ip_bytes)\n",
    "    )\n",
    "str(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t194980 obs. of  10 variables:\n",
      " $ ts           : num  1.33e+09 1.33e+09 1.33e+09 1.33e+09 1.33e+09 ...\n",
      " $ orig_port    : num  2633 4094 16066 42997 38566 ...\n",
      " $ resp_port    : num  80 80 12486 28745 32754 ...\n",
      " $ duration     : num  NA 0.01 NA NA NA NA NA NA NA 0.01 ...\n",
      " $ orig_bytes   : num  NA 7085 NA NA NA ...\n",
      " $ resp_bytes   : num  NA 172 NA NA NA NA NA NA NA 0 ...\n",
      " $ orig_pkts    : num  8 10 1 1 1 1 1 1 1 1 ...\n",
      " $ orig_ip_bytes: num  813 7497 48 60 48 ...\n",
      " $ resp_pkts    : num  9 9 1 1 1 1 1 1 1 1 ...\n",
      " $ resp_ip_bytes: num  8505 544 40 40 40 ...\n"
     ]
    }
   ],
   "source": [
    "dat2 <- subset(dat, select = -c(service,proto,conn_state,orig_ip,resp_ip,history,missed_bytes))\n",
    "str(dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 Ã— 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ts</th><th scope=col>orig_port</th><th scope=col>resp_port</th><th scope=col>duration</th><th scope=col>orig_bytes</th><th scope=col>resp_bytes</th><th scope=col>orig_pkts</th><th scope=col>orig_ip_bytes</th><th scope=col>resp_pkts</th><th scope=col>resp_ip_bytes</th><th scope=col>logduration</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1331915797</td><td> 2633</td><td>   80</td><td>  NA</td><td>  NA</td><td> NA</td><td> 8</td><td> 813</td><td>9</td><td>8505</td><td>      NA</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1331921224</td><td> 4094</td><td>   80</td><td>0.01</td><td>7085</td><td>172</td><td>10</td><td>7497</td><td>9</td><td> 544</td><td>-4.60517</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1331903910</td><td>16066</td><td>12486</td><td>  NA</td><td>  NA</td><td> NA</td><td> 1</td><td>  48</td><td>1</td><td>  40</td><td>      NA</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1331988939</td><td>42997</td><td>28745</td><td>  NA</td><td>  NA</td><td> NA</td><td> 1</td><td>  60</td><td>1</td><td>  40</td><td>      NA</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1331918792</td><td>38566</td><td>32754</td><td>  NA</td><td>  NA</td><td> NA</td><td> 1</td><td>  48</td><td>1</td><td>  40</td><td>      NA</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1331901863</td><td>63805</td><td>45078</td><td>  NA</td><td>  NA</td><td> NA</td><td> 1</td><td>  44</td><td>1</td><td>  40</td><td>      NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 Ã— 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & ts & orig\\_port & resp\\_port & duration & orig\\_bytes & resp\\_bytes & orig\\_pkts & orig\\_ip\\_bytes & resp\\_pkts & resp\\_ip\\_bytes & logduration\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1331915797 &  2633 &    80 &   NA &   NA &  NA &  8 &  813 & 9 & 8505 &       NA\\\\\n",
       "\t2 & 1331921224 &  4094 &    80 & 0.01 & 7085 & 172 & 10 & 7497 & 9 &  544 & -4.60517\\\\\n",
       "\t3 & 1331903910 & 16066 & 12486 &   NA &   NA &  NA &  1 &   48 & 1 &   40 &       NA\\\\\n",
       "\t4 & 1331988939 & 42997 & 28745 &   NA &   NA &  NA &  1 &   60 & 1 &   40 &       NA\\\\\n",
       "\t5 & 1331918792 & 38566 & 32754 &   NA &   NA &  NA &  1 &   48 & 1 &   40 &       NA\\\\\n",
       "\t6 & 1331901863 & 63805 & 45078 &   NA &   NA &  NA &  1 &   44 & 1 &   40 &       NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 Ã— 11\n",
       "\n",
       "| <!--/--> | ts &lt;dbl&gt; | orig_port &lt;dbl&gt; | resp_port &lt;dbl&gt; | duration &lt;dbl&gt; | orig_bytes &lt;dbl&gt; | resp_bytes &lt;dbl&gt; | orig_pkts &lt;dbl&gt; | orig_ip_bytes &lt;dbl&gt; | resp_pkts &lt;dbl&gt; | resp_ip_bytes &lt;dbl&gt; | logduration &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1331915797 |  2633 |    80 |   NA |   NA |  NA |  8 |  813 | 9 | 8505 |       NA |\n",
       "| 2 | 1331921224 |  4094 |    80 | 0.01 | 7085 | 172 | 10 | 7497 | 9 |  544 | -4.60517 |\n",
       "| 3 | 1331903910 | 16066 | 12486 |   NA |   NA |  NA |  1 |   48 | 1 |   40 |       NA |\n",
       "| 4 | 1331988939 | 42997 | 28745 |   NA |   NA |  NA |  1 |   60 | 1 |   40 |       NA |\n",
       "| 5 | 1331918792 | 38566 | 32754 |   NA |   NA |  NA |  1 |   48 | 1 |   40 |       NA |\n",
       "| 6 | 1331901863 | 63805 | 45078 |   NA |   NA |  NA |  1 |   44 | 1 |   40 |       NA |\n",
       "\n"
      ],
      "text/plain": [
       "  ts         orig_port resp_port duration orig_bytes resp_bytes orig_pkts\n",
       "1 1331915797  2633        80       NA       NA        NA         8       \n",
       "2 1331921224  4094        80     0.01     7085       172        10       \n",
       "3 1331903910 16066     12486       NA       NA        NA         1       \n",
       "4 1331988939 42997     28745       NA       NA        NA         1       \n",
       "5 1331918792 38566     32754       NA       NA        NA         1       \n",
       "6 1331901863 63805     45078       NA       NA        NA         1       \n",
       "  orig_ip_bytes resp_pkts resp_ip_bytes logduration\n",
       "1  813          9         8505                NA   \n",
       "2 7497          9          544          -4.60517   \n",
       "3   48          1           40                NA   \n",
       "4   60          1           40                NA   \n",
       "5   48          1           40                NA   \n",
       "6   44          1           40                NA   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat2[,\"logduration\"]=log(dat2[,\"duration\"])\n",
    "head(dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(462)\n",
    "completed_data <- amelia(dat2,m=5,p2s=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.amelia(obj=completed_data,file.stem=\"G:\\\\Users\\\\Gabriel\\\\Documents\\\\Education\\\\UoB\\\\GitHubDesktop\\\\DST-Assessment-02\\\\Data\\\\amelia_predict_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function writes our 5 amelia outputs to 5 seperate csv files, one for each imputation. Which we can access using the usual methods. I tried to find a way to combine these into a singular dataset but with much exploration, and many failed attempts ended up running out of time to do so, thus for analysis will look at the results of just one selected at random.\n",
    "\n",
    "A better implementation of non-trivial models follows in the next document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[About Amelia pdf](https://cran.r-project.org/web/packages/Amelia/vignettes/amelia.pdf)\n",
    "\n",
    "[Amelia R Documentation](https://www.rdocumentation.org/packages/Amelia/versions/1.7.6)\n",
    "\n",
    "[MICE R Documentation](https://www.rdocumentation.org/packages/mice/versions/3.12.0/topics/mice)\n",
    "\n",
    "[Data Science article about imputing data with MICE](https://datascienceplus.com/imputing-missing-data-with-r-mice-package/)\n",
    "\n",
    "[Medium article about usage with MICE](https://medium.com/coinmonks/dealing-with-missing-data-using-r-3ae428da2d17)\n",
    "\n",
    "[Using Amelia](https://www.linkedin.com/pulse/amelia-packager-missing-data-imputation-ramprakash-veluchamy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
